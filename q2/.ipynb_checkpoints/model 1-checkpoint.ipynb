{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS520 Final Q2\n",
    "\n",
    "### Madhumitha Sivaraj\n",
    "https://docs.google.com/document/d/1pzw7Z_Z1YijAs6RgpLRjyfxlc8LSJcAjOPIrRjaSe9M/edit?folder=19omk6ges1yPjEJ-QRZpMDfIEreLo_eH1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a model to classify images as Class A or B, and train it on the indicated data. You must code your own model from scratch. Specify your trained model. What does your model predict for each of the unlabeled images? Give the details of your model, its training, and the final result. Do the predictions make sense, to you?\n",
    "\n",
    "Be very clear about what model you're using, the math you used to train it, etc etc. Why would a huge neural network be a bad idea here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def init(x):\n",
    "    weights=np.zeros((x.shape[0],1))\n",
    "    bias=0\n",
    "    return weights, bias\n",
    "\n",
    "def prop(weights, bias, x, y):\n",
    "    activation=sigmoid(np.dot(weights.T,x)+ bias) \n",
    "    cost=(1/x.shape[1])*(np.sum(np.square(y-np.dot(weights.T,x))))\n",
    "    return activation, cost\n",
    "\n",
    "def gradient_descent(activation, x, y):\n",
    "    weights=(1/x.shape[1])*np.dot(x,np.subtract(activation,y).T)\n",
    "    bias=(1/x.shape[1])*np.sum(activation-y)\n",
    "    return weights, bias\n",
    "\n",
    "def lossWithRegularization(weights,size,lambd):\n",
    "    loss = lambd/(2*size)*(np.sum(np.square(weights)))\n",
    "    return loss\n",
    "\n",
    "def LRpropagate(weights, bias, x, y):\n",
    "    size = x.shape[1]\n",
    "    # forward propagation\n",
    "    p = np.dot(weights.T,x)+bias\n",
    "    loss = np.sum(np.square(y-np.dot(weights.T,x)))*1/size\n",
    "#     loss = loss + lossWithRegularization(weights,size, 0.005)\n",
    "    \n",
    "    # backward propagration\n",
    "    d_weights = (2/size)*np.dot(x, (p-y).T)+0.005/size*weights\n",
    "    d_bais = (2/size)*(p-y)\n",
    "    return loss, d_weights, d_bais\n",
    "\n",
    "def LRtrain(weights, bias, x, y, iterations, rate):\n",
    "    z = []\n",
    "    for i in range(iterations):\n",
    "        loss, weights2, d_bais = LRpropagate(weights, bias, x, y)\n",
    "        weights = weights-rate*weights2\n",
    "        \n",
    "        if i %100 ==0:\n",
    "            z.append(loss)\n",
    "        \n",
    "    return weights, bias, weights2, d_bais, z\n",
    "\n",
    "def LRpredict(weights, bias, x):\n",
    "    size = x.shape[1]\n",
    "    predict_y = np.zeros((1,size))\n",
    "    weights = weights.reshape(x.shape[0],1)\n",
    "    p = np.dot(weights.T,x)\n",
    "    for i in range(p.shape[1]):\n",
    "        if abs(p[0,i]-0) < abs(p[0,i]-1):\n",
    "            predict_y[0,i] = 0\n",
    "        elif abs(p[0,i]-0) >= abs(p[0,i]-1):\n",
    "            predict_y[0,i] = 1\n",
    "    return predict_y, p\n",
    "\n",
    "class_a = np.loadtxt('class_a.txt', usecols=range(5))\n",
    "class_b = np.loadtxt('class_b.txt', usecols=range(5))\n",
    "mystery = np.loadtxt('mystery.txt', usecols=range(5))\n",
    "mystery1 = np.reshape(mystery[0:5],(1,25))\n",
    "mystery2 = np.reshape(mystery[5:10],(1,25))\n",
    "mystery3 = np.reshape(mystery[10:15],(1,25))\n",
    "mystery4 = np.reshape(mystery[15:20],(1,25))\n",
    "mystery5 = np.reshape(mystery[20:25],(1,25))\n",
    "class_a1 = np.reshape(class_a[0:5],(1,25))\n",
    "class_a2 = np.reshape(class_a[5:10],(1,25))\n",
    "class_a3 = np.reshape(class_a[10:15],(1,25))\n",
    "class_a4 = np.reshape(class_a[15:20],(1,25))\n",
    "class_a5 = np.reshape(class_a[20:25],(1,25))\n",
    "class_b1 = np.reshape(class_b[0:5],(1,25))\n",
    "class_b2 = np.reshape(class_b[5:10],(1,25))\n",
    "class_b3 = np.reshape(class_b[10:15],(1,25))\n",
    "class_b4 = np.reshape(class_b[15:20],(1,25))\n",
    "class_b5 = np.reshape(class_b[20:25],(1,25))\n",
    "train_x = np.concatenate((class_a1,class_a2,class_a3,class_a4,class_a5,class_b1,class_b2,class_b3,class_b4,class_b5))\n",
    "train_x = train_x.T\n",
    "train_y = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "test_x = np.concatenate((mystery1,mystery2,mystery3,mystery4,mystery5))\n",
    "test_x = test_x.T\n",
    "\n",
    "LRtrain_x = np.append(train_x,np.array([[1,1,1,1,1,1,1,1,1,1]]),axis=0)\n",
    "weights,bias = initialize(train_x)\n",
    "weights, bias, d_weights, d_bais, z = LRtrain(weights,bias,train_x,train_y,2000,0.05)\n",
    "predict_y3, p3 = LRpredict(weights, bias, test_x)\n",
    "predict_y3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'A', 'B', 'A', 'B']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def l2(weights, x, lamda):\n",
    "    loss=lamda/(2*x.shape[1])*(np.sum(weights))\n",
    "    return loss\n",
    "\n",
    "def init(x):\n",
    "    weights=np.zeros((x.shape[0],1))\n",
    "    bias=0\n",
    "    return weights, bias\n",
    "\n",
    "def prop(weights, bias, x, y):\n",
    "    activation=np.dot(weights.T,x)\n",
    "    cost=(1/x.shape[1])*(np.sum(np.square(y-np.dot(weights.T,x))))\n",
    "    cost += l2(weights,x,0.005)\n",
    "    return activation, cost\n",
    "\n",
    "def back_prop(activation, x, y):\n",
    "    weights=(2/x.shape[1])*np.dot(x,np.subtract(activation,y).T) + 0.005/size*weights\n",
    "    bias=(2/x.shape[1])*np.subtract(activation,y)\n",
    "    return weights, bias\n",
    "\n",
    "def train(weights, bias, x, y, iterations, lr):\n",
    "    for i in range(iterations):\n",
    "        activation, cost = prop(weights, bias, x, y)\n",
    "        w,b=gradient_descent(activation, x, y)\n",
    "        weights= weights-lr*w\n",
    "        bias = bias-lr*b    \n",
    "    return weights, bias\n",
    "\n",
    "def predict(weights, bias, x):\n",
    "    y_predict=[]\n",
    "    weights = weights.reshape(x.shape[0],1)\n",
    "    activation = sigmoid(np.dot(weights.T,x)+bias)\n",
    "    for i in range(activation.shape[1]):\n",
    "        if abs(activation[0,i]-0)<abs(activation[0,i]-1):\n",
    "            y_predict.append('A')\n",
    "        elif abs(activation[0,i]-0)>=abs(activation[0,i]-1):\n",
    "            y_predict.append('B')\n",
    "    return y_predict\n",
    "\n",
    "\n",
    "class_a = np.loadtxt('class_a.txt', usecols=range(5))\n",
    "class_b = np.loadtxt('class_b.txt', usecols=range(5))\n",
    "mystery = np.loadtxt('mystery.txt', usecols=range(5))\n",
    "mystery1 = np.reshape(mystery[0:5],(1,25))\n",
    "mystery2 = np.reshape(mystery[5:10],(1,25))\n",
    "mystery3 = np.reshape(mystery[10:15],(1,25))\n",
    "mystery4 = np.reshape(mystery[15:20],(1,25))\n",
    "mystery5 = np.reshape(mystery[20:25],(1,25))\n",
    "class_a1 = np.reshape(class_a[0:5],(1,25))\n",
    "class_a2 = np.reshape(class_a[5:10],(1,25))\n",
    "class_a3 = np.reshape(class_a[10:15],(1,25))\n",
    "class_a4 = np.reshape(class_a[15:20],(1,25))\n",
    "class_a5 = np.reshape(class_a[20:25],(1,25))\n",
    "class_b1 = np.reshape(class_b[0:5],(1,25))\n",
    "class_b2 = np.reshape(class_b[5:10],(1,25))\n",
    "class_b3 = np.reshape(class_b[10:15],(1,25))\n",
    "class_b4 = np.reshape(class_b[15:20],(1,25))\n",
    "class_b5 = np.reshape(class_b[20:25],(1,25))\n",
    "train_x = np.concatenate((class_a1,class_a2,class_a3,class_a4,class_a5,class_b1,class_b2,class_b3,class_b4,class_b5))\n",
    "train_x = train_x.T\n",
    "train_y = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "test_x = np.concatenate((mystery1,mystery2,mystery3,mystery4,mystery5))\n",
    "test_x = test_x.T\n",
    "\n",
    "\n",
    "LRtrain_x = np.append(train_x,np.array([[1,1,1,1,1,1,1,1,1,1]]),axis=0)\n",
    "weights,bias = init(train_x)\n",
    "weights, bias = train(weights,bias,train_x,train_y,2000,0.05)\n",
    "predict_y3 = predict(weights, bias, test_x)\n",
    "predict_y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
